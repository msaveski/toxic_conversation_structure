{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../processing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from _config import Config\n",
    "from prediction_next_reply import load_data, make_paired_dataset\n",
    "from prediction_prefix import sanitize_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GB_model(n_folds, n_jobs):\n",
    "    grid = {\n",
    "        \"clf__n_estimators\": [10, 25, 50, 100, 500, 1000, 2000, 3000, 5000, 10000]\n",
    "        # \"clf__n_estimators\": [10, 25]   \n",
    "    }\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "        (\"std\", StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    "        (\"clf\", LGBMClassifier(random_state=0))\n",
    "    ])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        estimator=pipe, \n",
    "        param_grid=grid, \n",
    "        cv=skf,\n",
    "        n_jobs=n_jobs,\n",
    "        scoring=\"accuracy\",\n",
    "        refit=True\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "cv_n_folds = 10\n",
    "cv_n_jobs = 10\n",
    "\n",
    "feature_sets = [\n",
    "    \"conversation_state\",\n",
    "    \"user_info\",\n",
    "    \"alignments\",\n",
    "    \"follow_di\",\n",
    "    \"follow_ud\",\n",
    "    \"reply_di\",\n",
    "    \"reply_ud\",\n",
    "    \"dyad_up\",\n",
    "    \"dyad_ur\",\n",
    "    \"embeddedness_all\",\n",
    "    \"embeddedness_toxicity\",\n",
    "    \"embeddedness_follow\",\n",
    "    \"embeddedness_reply\",\n",
    "    \"tree\"    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193040, 273) (100286, 273)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X_nw, y_nw, meta_nw, fnames_nw = load_data(\"news\", feature_sets)\n",
    "X_mt, y_mt, meta_mt, fnames_mt = load_data(\"midterms\", feature_sets)\n",
    "\n",
    "assert fnames_nw == fnames_mt\n",
    "fnames = fnames_nw\n",
    "\n",
    "print(X_nw.shape, X_mt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193040, 269) (100286, 269)\n"
     ]
    }
   ],
   "source": [
    "# sanitize\n",
    "_, fnames_new_nw, _ = sanitize_x(X_nw, fnames_nw)\n",
    "_, fnames_new_mt, _ = sanitize_x(X_mt, fnames_mt)\n",
    "\n",
    "# intersect features\n",
    "fnames_new_nw = [tuple(i) for i in fnames_new_nw]\n",
    "fnames_new_mt = [tuple(i) for i in fnames_new_mt]\n",
    "\n",
    "fnames_int = set(fnames_new_nw) & set(fnames_new_mt)\n",
    "fnames_int_idxs = sorted([fnames.index(common) for common in fnames_int])\n",
    "\n",
    "# filter\n",
    "X_nw = X_nw[:, fnames_int_idxs]\n",
    "X_mt = X_mt[:, fnames_int_idxs]\n",
    "\n",
    "assert X_nw.shape[1] == X_mt.shape[1]\n",
    "\n",
    "print(X_nw.shape, X_mt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make paired datasets\n",
    "X_nw_pairs, y_nw_pairs, meta_nw_pairs = make_paired_dataset(X_nw, y_nw, meta_nw)\n",
    "X_mt_pairs, y_mt_pairs, meta_mt_pairs = make_paired_dataset(X_mt, y_mt, meta_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "X_nw_pairs_train, X_nw_pairs_test, y_nw_pairs_train, y_nw_pairs_test = \\\n",
    "    train_test_split(X_nw_pairs, y_nw_pairs, test_size=0.2, random_state=0)\n",
    "\n",
    "X_mt_pairs_train, X_mt_pairs_test, y_mt_pairs_train, y_mt_pairs_test = \\\n",
    "    train_test_split(X_mt_pairs, y_mt_pairs, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('imp', SimpleImputer()),\n",
       "                                       ('std', StandardScaler()),\n",
       "                                       ('clf',\n",
       "                                        LGBMClassifier(random_state=0))]),\n",
       "             n_jobs=10,\n",
       "             param_grid={'clf__n_estimators': [10, 25, 50, 100, 500, 1000, 2000,\n",
       "                                               3000, 5000, 10000]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# news model\n",
    "model_nw = get_GB_model(n_folds=cv_n_folds, n_jobs=cv_n_jobs)\n",
    "model_nw.fit(X_nw_pairs_train, y_nw_pairs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('imp', SimpleImputer()),\n",
       "                                       ('std', StandardScaler()),\n",
       "                                       ('clf',\n",
       "                                        LGBMClassifier(random_state=0))]),\n",
       "             n_jobs=10,\n",
       "             param_grid={'clf__n_estimators': [10, 25, 50, 100, 500, 1000, 2000,\n",
       "                                               3000, 5000, 10000]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# midterms model\n",
    "model_mt = get_GB_model(n_folds=cv_n_folds, n_jobs=cv_n_jobs)\n",
    "model_mt.fit(X_mt_pairs_train, y_mt_pairs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    # news\n",
    "    \"news_train\": accuracy_score(model_nw.predict(X_nw_pairs_train), y_nw_pairs_train),\n",
    "    \"news_news_test\": accuracy_score(model_nw.predict(X_nw_pairs_test), y_nw_pairs_test),\n",
    "    \"news_midterms_test\": accuracy_score(model_nw.predict(X_mt_pairs_test), y_mt_pairs_test),\n",
    "    # midterms\n",
    "    \"midterms_train\": accuracy_score(model_mt.predict(X_mt_pairs_train), y_mt_pairs_train),\n",
    "    \"midterms_midterms_test\": accuracy_score(model_mt.predict(X_mt_pairs_test), y_mt_pairs_test),\n",
    "    \"midterms_news_test\": accuracy_score(model_mt.predict(X_nw_pairs_test), y_nw_pairs_test)       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to JSON\n",
    "out_fpath = f\"{Config().modeling_dir}/next_reply/runs/domain_transfer.json.gz\"\n",
    "\n",
    "with gzip.open(out_fpath, \"wt\") as fout:\n",
    "    json.dump(res, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_train': 0.8507304185661003,\n",
       " 'news_news_test': 0.7139970990468296,\n",
       " 'news_midterms_test': 0.7361651211486688,\n",
       " 'midterms_train': 0.7952335842847884,\n",
       " 'midterms_midterms_test': 0.7425466148170307,\n",
       " 'midterms_news_test': 0.705605055946954}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('dtox': virtualenv)",
   "language": "python",
   "name": "python37264bitdtoxvirtualenvbf1c2042b6b64ee8b97dfe3287fe0a24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
